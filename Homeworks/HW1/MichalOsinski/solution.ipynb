{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Used dataset: SpeedDating.csv with imbalance ratio 4.63:\n",
    "\n",
    "# Processing\n",
    "\n",
    "Data is split 80/20 (train, test).\n",
    "\n",
    "# Results\n",
    "\n",
    "![Accuracy plot](accuracy.png)\n",
    "![Precision plot](precision.png)\n",
    "![Recall plot](recall.png)\n",
    "\n",
    "Although all three models show similar accuracies on test data, Random Forest is clearly more fitted to train data than the rest. Despite this fact, Gradient Boosting shows better precision on test data. All models show a lot of false positives, probably due to the imbalance in the dataset. All models also struggled in terms of recall, with Random Forest achieving >60% recall. It's hard to determine the best model for this dataset but clearly Logistic Regression is not the one with the worst performance across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
