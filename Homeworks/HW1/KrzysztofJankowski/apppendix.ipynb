{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix - HW 1 Krzysztof Jankowski"
      ],
      "metadata": {
        "collapsed": false,
        "id": "t0uKACGTLkzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching the dataset and first analysis."
      ],
      "metadata": {
        "collapsed": false,
        "id": "mwL_34X-Lkzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1109, 21)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "X, y = fetch_openml('pc1', return_X_y=True)\n",
        "X.head()\n",
        "print(X.shape)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-10T19:36:54.294987145Z",
          "start_time": "2023-10-10T19:36:54.245825654Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgC0rKWxLkzf",
        "outputId": "bf798c4c-4f90-4573-96fb-20ac5b84b6fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1032\n",
            "77\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               loc         v(g)        ev(g)        iv(G)            N  \\\n",
              "count  1109.000000  1109.000000  1109.000000  1109.000000  1109.000000   \n",
              "mean     23.376105     5.510730     2.766817     3.321371   117.393417   \n",
              "std      35.284017     8.958976     5.567704     6.401998   197.336888   \n",
              "min       0.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "25%       7.000000     1.000000     1.000000     1.000000    25.000000   \n",
              "50%      13.000000     3.000000     1.000000     2.000000    58.000000   \n",
              "75%      26.000000     6.000000     3.000000     3.000000   126.000000   \n",
              "max     602.000000   136.000000   123.000000   123.000000  2785.000000   \n",
              "\n",
              "                  V            L            D            I             E  ...  \\\n",
              "count   1109.000000  1109.000000  1109.000000  1109.000000  1.109000e+03  ...   \n",
              "mean     699.711217     0.129414    15.396267    32.904472  2.882288e+04  ...   \n",
              "std     1509.545684     0.146952    16.337508    35.387685  1.706436e+05  ...   \n",
              "min        0.000000     0.000000     0.000000     0.000000  0.000000e+00  ...   \n",
              "25%       97.670000     0.050000     5.710000    14.040000  5.581300e+02  ...   \n",
              "50%      275.100000     0.080000    11.610000    23.570000  3.189170e+03  ...   \n",
              "75%      674.040000     0.160000    20.500000    41.150000  1.238156e+04  ...   \n",
              "max    25942.690000     2.000000   270.660000   598.330000  4.279633e+06  ...   \n",
              "\n",
              "                   T       lOCode    lOComment  locCodeAndComment  \\\n",
              "count    1109.000000  1109.000000  1109.000000        1109.000000   \n",
              "mean     1601.273030    22.434626     4.696123           0.944995   \n",
              "std      9480.199989    33.574645    10.518447           3.345297   \n",
              "min         0.000000     0.000000     0.000000           0.000000   \n",
              "25%        31.010000     7.000000     0.000000           0.000000   \n",
              "50%       177.180000    13.000000     0.000000           0.000000   \n",
              "75%       687.860000    24.000000     5.000000           1.000000   \n",
              "max    237757.400000   600.000000   159.000000          48.000000   \n",
              "\n",
              "           lOBlank      uniq_Op    uniq_Opnd     total_Op   total_Opnd  \\\n",
              "count  1109.000000  1109.000000  1109.000000  1109.000000  1109.000000   \n",
              "mean      6.745717    13.307665    20.892876    66.493417    50.901894   \n",
              "std      12.301210     8.182224    29.051434   111.703236    86.308689   \n",
              "min       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
              "25%       1.000000     8.000000     6.000000    15.000000    10.000000   \n",
              "50%       2.000000    12.000000    12.000000    33.000000    24.000000   \n",
              "75%       8.000000    17.000000    25.000000    72.000000    56.000000   \n",
              "max     225.000000    99.000000   538.000000  1641.000000  1144.000000   \n",
              "\n",
              "       branchCount  \n",
              "count  1109.000000  \n",
              "mean      9.576555  \n",
              "std      16.540676  \n",
              "min       1.000000  \n",
              "25%       1.000000  \n",
              "50%       5.000000  \n",
              "75%      11.000000  \n",
              "max     236.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af3bf0d9-52d8-4b2f-acbb-4ba6a605a092\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>v(g)</th>\n",
              "      <th>ev(g)</th>\n",
              "      <th>iv(G)</th>\n",
              "      <th>N</th>\n",
              "      <th>V</th>\n",
              "      <th>L</th>\n",
              "      <th>D</th>\n",
              "      <th>I</th>\n",
              "      <th>E</th>\n",
              "      <th>...</th>\n",
              "      <th>T</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1.109000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "      <td>1109.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.376105</td>\n",
              "      <td>5.510730</td>\n",
              "      <td>2.766817</td>\n",
              "      <td>3.321371</td>\n",
              "      <td>117.393417</td>\n",
              "      <td>699.711217</td>\n",
              "      <td>0.129414</td>\n",
              "      <td>15.396267</td>\n",
              "      <td>32.904472</td>\n",
              "      <td>2.882288e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>1601.273030</td>\n",
              "      <td>22.434626</td>\n",
              "      <td>4.696123</td>\n",
              "      <td>0.944995</td>\n",
              "      <td>6.745717</td>\n",
              "      <td>13.307665</td>\n",
              "      <td>20.892876</td>\n",
              "      <td>66.493417</td>\n",
              "      <td>50.901894</td>\n",
              "      <td>9.576555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>35.284017</td>\n",
              "      <td>8.958976</td>\n",
              "      <td>5.567704</td>\n",
              "      <td>6.401998</td>\n",
              "      <td>197.336888</td>\n",
              "      <td>1509.545684</td>\n",
              "      <td>0.146952</td>\n",
              "      <td>16.337508</td>\n",
              "      <td>35.387685</td>\n",
              "      <td>1.706436e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>9480.199989</td>\n",
              "      <td>33.574645</td>\n",
              "      <td>10.518447</td>\n",
              "      <td>3.345297</td>\n",
              "      <td>12.301210</td>\n",
              "      <td>8.182224</td>\n",
              "      <td>29.051434</td>\n",
              "      <td>111.703236</td>\n",
              "      <td>86.308689</td>\n",
              "      <td>16.540676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>97.670000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>5.710000</td>\n",
              "      <td>14.040000</td>\n",
              "      <td>5.581300e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>31.010000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>275.100000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>11.610000</td>\n",
              "      <td>23.570000</td>\n",
              "      <td>3.189170e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>177.180000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>674.040000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>41.150000</td>\n",
              "      <td>1.238156e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>687.860000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>602.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>2785.000000</td>\n",
              "      <td>25942.690000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>270.660000</td>\n",
              "      <td>598.330000</td>\n",
              "      <td>4.279633e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>237757.400000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>538.000000</td>\n",
              "      <td>1641.000000</td>\n",
              "      <td>1144.000000</td>\n",
              "      <td>236.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af3bf0d9-52d8-4b2f-acbb-4ba6a605a092')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af3bf0d9-52d8-4b2f-acbb-4ba6a605a092 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af3bf0d9-52d8-4b2f-acbb-4ba6a605a092');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dae9e1a3-e98a-4bc7-9896-635ba02f49d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dae9e1a3-e98a-4bc7-9896-635ba02f49d6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dae9e1a3-e98a-4bc7-9896-635ba02f49d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.hist(y)\n",
        "\n",
        "print(np.sum(y == 'false'))\n",
        "print(np.sum(y == 'true'))\n",
        "\n",
        "X.describe()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-10T19:36:54.648255799Z",
          "start_time": "2023-10-10T19:36:54.311316319Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "XOJI0EFKLkzh",
        "outputId": "f6721344-80d1-47ed-9461-89176365dff5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data split and testing models."
      ],
      "metadata": {
        "collapsed": false,
        "id": "9rqUc2-PLkzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabpfn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5kb8AVgLwAH",
        "outputId": "4c2ec4e7-8cdf-485f-d151-e7102a9f6931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabpfn\n",
            "  Downloading tabpfn-0.1.9-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.0.1+cu118)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->tabpfn) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->tabpfn) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\n",
            "Installing collected packages: tabpfn\n",
            "Successfully installed tabpfn-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have to download the TabPFN, as there is no checkpoint at  /usr/local/lib/python3.10/dist-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\n",
            "It has about 100MB, so this might take a moment.\n",
            "Loading model that can be used for inference only\n",
            "Using a Transformer with 25.82 M parameters\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "default_models = {\n",
        "    'logistic_regression': LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
        "    'random_forest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    'xgboost': XGBClassifier(random_state=42, n_jobs=-1),\n",
        "    'tabpfn': TabPFNClassifier(device='cpu', N_ensemble_configurations=2),\n",
        "}\n",
        "\n",
        "scaler_dict = {\n",
        "    'logistic_regression': standard_scaler,\n",
        "    'random_forest': standard_scaler,\n",
        "    'xgboost': standard_scaler,\n",
        "    'tabpfn': None,\n",
        "}\n",
        "\n",
        "grids = {\n",
        "    'logistic_regression': dict(solver=['liblinear', 'lbfgs'], penalty=['none', 'l2'], C=[100, 10, 1.0, 0.1, 0.01]),\n",
        "    'random_forest': dict(n_estimators=[1, 2, 10, 50, 100], max_depth=[2, 10, 50, None]),\n",
        "    'xgboost': dict(max_depth=[1, 2, 6, 10], eta=[1, 0.3, 0.1], alpha=[1, 0]),\n",
        "    # 'tabpfn': dict(N_ensemble_configurations=[2, 16, 32]), # Gives memory leak error in gridsearch and takes too much resources.\n",
        "}\n",
        "\n",
        "models_dict = {\n",
        "    'logistic_regression': LogisticRegression,\n",
        "    'random_forest': RandomForestClassifier,\n",
        "    'xgboost': XGBClassifier,\n",
        "    'tabpfn': TabPFNClassifier,\n",
        "}\n",
        "\n",
        "def benchmark_models(models, metric):\n",
        "    for name, model in models.items():\n",
        "        standard_scaler = scaler_dict[name]\n",
        "        pipe = Pipeline(steps=[('scaler', standard_scaler), ('classifier', model)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        bac: float = metric(y_test, y_pred)\n",
        "        print(f'{name}: {bac:.3f}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-10T19:36:55.011126318Z",
          "start_time": "2023-10-10T19:36:54.632150405Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogHLeIxSLkzi",
        "outputId": "60668eac-5ce4-451c-b857-0d6bfb3be569"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data with stratify=None\n",
            "X_train shape: (887, 21), y_train shape: (887,), X_test shape: (222, 21), y_test shape: (222,)\n",
            "logistic_regression: 0.548\n",
            "random_forest: 0.548\n",
            "xgboost: 0.598\n",
            "tabpfn: 0.579\n",
            "Starting gridSearch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "150 fits failed out of a total of 600.\n",
            "The score on these train-test partitions for these parameters will be set to 0.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistic_regression: Best: 0.577 using {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "random_forest: Best: 0.637 using {'max_depth': 10, 'n_estimators': 1}\n",
            "xgboost: Best: 0.638 using {'alpha': 0, 'eta': 0.3, 'max_depth': 10}\n",
            "Benchmarking models after grid search\n",
            "logistic_regression: 0.498\n",
            "random_forest: 0.612\n",
            "xgboost: 0.593\n",
            "Splitting data with stratify=y\n",
            "X_train shape: (887, 21), y_train shape: (887,), X_test shape: (222, 21), y_test shape: (222,)\n",
            "logistic_regression: 0.529\n",
            "random_forest: 0.659\n",
            "xgboost: 0.724\n",
            "tabpfn: 0.600\n",
            "Starting gridSearch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "150 fits failed out of a total of 600.\n",
            "The score on these train-test partitions for these parameters will be set to 0.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistic_regression: Best: 0.576 using {'C': 100, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "random_forest: Best: 0.610 using {'max_depth': 10, 'n_estimators': 1}\n",
            "xgboost: Best: 0.626 using {'alpha': 0, 'eta': 1, 'max_depth': 6}\n",
            "Benchmarking models after grid search\n",
            "logistic_regression: 0.562\n",
            "random_forest: 0.578\n",
            "xgboost: 0.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
        "\n",
        "for s in [None, y]:\n",
        "    print('Splitting data with stratify=y' if s is not None else 'Splitting data with stratify=None')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=s)\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "    print(\n",
        "        f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
        "\n",
        "    benchmark_models(default_models, balanced_accuracy_score)\n",
        "\n",
        "    print('Starting gridSearch')\n",
        "    optimized_models = {}\n",
        "    for name, model in default_models.items():\n",
        "        if name not in grids:\n",
        "            continue\n",
        "        grid = grids[name]\n",
        "        cv = RepeatedStratifiedKFold(n_splits=3, random_state=42)\n",
        "        grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='balanced_accuracy',\n",
        "                                   error_score=0)\n",
        "        grid_result = grid_search.fit(X_train, y_train)\n",
        "        # summarize results\n",
        "        print(f'{name}: Best: {grid_result.best_score_:.3f} using {grid_result.best_params_}')\n",
        "\n",
        "        optimized_models[name] = models_dict[name](random_state=42, **grid_result.best_params_)\n",
        "\n",
        "    print('Benchmarking models after grid search')\n",
        "    benchmark_models(optimized_models, balanced_accuracy_score)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-10T19:39:09.290841951Z",
          "start_time": "2023-10-10T19:37:19.940330615Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikEt5NRfLkzj",
        "outputId": "df4cd018-6f26-4c98-e17a-cdc3ef7fbe58"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}