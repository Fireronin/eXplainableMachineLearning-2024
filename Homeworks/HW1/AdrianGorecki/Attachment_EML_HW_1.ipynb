{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adrianstando/imbalanced-benchmarking-set/raw/main/datasets/wine_quality.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI1l5kIXWRpb",
        "outputId": "4c37ea9f-d690-40e5-bba3-db86f98c96bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-12 19:44:55--  https://github.com/adrianstando/imbalanced-benchmarking-set/raw/main/datasets/wine_quality.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianstando/imbalanced-benchmarking-set/main/datasets/wine_quality.csv [following]\n",
            "--2023-10-12 19:44:55--  https://raw.githubusercontent.com/adrianstando/imbalanced-benchmarking-set/main/datasets/wine_quality.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315368 (308K) [text/plain]\n",
            "Saving to: ‘wine_quality.csv.2’\n",
            "\n",
            "wine_quality.csv.2  100%[===================>] 307.98K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-12 19:44:55 (6.21 MB/s) - ‘wine_quality.csv.2’ saved [315368/315368]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "g7F-XmgaZZPo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3ET8WoyaRnOK"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('wine_quality.csv', index_col=0)\n",
        "\n",
        "X = dataset.drop('TARGET', axis=1)\n",
        "y = dataset['TARGET']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32) / 2 + 0.5\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32) / 2 + 0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearRegressionModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(11, 32)\n",
        "    self.fc2 = nn.Linear(32, 64)\n",
        "    self.fc3 = nn.Linear(64, 32)\n",
        "    self.fc4 = nn.Linear(32, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = F.sigmoid(self.fc4(x))\n",
        "    return x.flatten()\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    y_pred = model(X_train)\n",
        "\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "linearRegressionAccuracy = 0.0\n",
        "linearRegressionReport = \"\"\n",
        "with torch.no_grad():\n",
        "  y_eval = model(X_test)\n",
        "  y_eval = y_eval > 0.5\n",
        "\n",
        "  linearRegressionAccuracy = accuracy_score(y_test, y_eval)\n",
        "  print(f'Accuracy: {linearRegressionAccuracy:%}')\n",
        "  linearRegressionReport = classification_report(y_test, y_eval, digits=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r_Yj76fWol2",
        "outputId": "d2c80040-c7a3-4139-cb64-6259a7e2fe09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.428571%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomForest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "randomForest.fit(X_train, y_train)\n",
        "\n",
        "y_eval = randomForest.predict(X_test)\n",
        "\n",
        "randomForestAccuracy = accuracy_score(y_test, y_eval)\n",
        "print(f'Accuracy: {randomForestAccuracy:%}')\n",
        "randomForestReport = classification_report(y_test, y_eval, digits=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elPXs18JLjc7",
        "outputId": "44e8d146-2beb-4227-c761-986e9807fa67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.448980%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradientBoosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gradientBoosting.fit(X_train, y_train)\n",
        "\n",
        "y_eval = gradientBoosting.predict(X_test)\n",
        "\n",
        "gradientBoostingAccuracy = accuracy_score(y_test, y_eval)\n",
        "print(f'Accuracy: {gradientBoostingAccuracy:%}')\n",
        "gradientBoostingReport = classification_report(y_test, y_eval, digits=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9G7ABQUMHkL",
        "outputId": "4dc16081-c50f-44d6-9d5b-4bb57e2eded6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.142857%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabpfn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkHKlxYHaKUT",
        "outputId": "f0fa93f2-18c9-4119-8ee0-1eee58302526"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabpfn in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.0.1+cu118)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->tabpfn) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->tabpfn) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabpfn import TabPFNClassifier\n",
        "\n",
        "classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=32)\n",
        "\n",
        "classifier.fit(X_train[:1000], y_train[:1000], overwrite_warning=True)\n",
        "y_eval = classifier.predict(X_test)\n",
        "\n",
        "tabPFNAccuracy = accuracy_score(y_test, y_eval)\n",
        "print(f'Accuracy: {tabPFNAccuracy:%}')\n",
        "tabPFNReport = classification_report(y_test, y_eval, digits=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQrHiPGIaAm6",
        "outputId": "d0277f01-fe2c-49eb-fbdb-099ebba842da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model that can be used for inference only\n",
            "Using a Transformer with 25.82 M parameters\n",
            "Accuracy: 96.938776%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear Regression:\")\n",
        "print(linearRegressionReport)\n",
        "print(\"Random Forest:\")\n",
        "print(randomForestReport)\n",
        "print(\"Gradient Boosting:\")\n",
        "print(gradientBoostingReport)\n",
        "print(\"TabPFN:\")\n",
        "print(tabPFNReport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mF-f0HtYm-S",
        "outputId": "db291ccc-91ab-499a-e179-f7d5489c363d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9721    0.9916    0.9818       950\n",
            "         1.0     0.2727    0.1000    0.1463        30\n",
            "\n",
            "    accuracy                         0.9643       980\n",
            "   macro avg     0.6224    0.5458    0.5641       980\n",
            "weighted avg     0.9507    0.9643    0.9562       980\n",
            "\n",
            "Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9763    0.9979    0.9870       950\n",
            "         1.0     0.7778    0.2333    0.3590        30\n",
            "\n",
            "    accuracy                         0.9745       980\n",
            "   macro avg     0.8770    0.6156    0.6730       980\n",
            "weighted avg     0.9702    0.9745    0.9678       980\n",
            "\n",
            "Gradient Boosting:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9772    0.9937    0.9854       950\n",
            "         1.0     0.5714    0.2667    0.3636        30\n",
            "\n",
            "    accuracy                         0.9714       980\n",
            "   macro avg     0.7743    0.6302    0.6745       980\n",
            "weighted avg     0.9648    0.9714    0.9664       980\n",
            "\n",
            "TabPFN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9694    1.0000    0.9845       950\n",
            "         1.0     0.0000    0.0000    0.0000        30\n",
            "\n",
            "    accuracy                         0.9694       980\n",
            "   macro avg     0.4847    0.5000    0.4922       980\n",
            "weighted avg     0.9397    0.9694    0.9543       980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset I chose for this task was wine_quality with imbalance ration of 25.77 and 11 columns.\n",
        "\n",
        "From the models I've tested Random Forest and Gradient Boosting seems to be performing the best, as they both have the biggest accuracy on the whole dataset and on the samples where the target was equal to \"1\" (though it's worth noting that in that case their accuracy was around 35%, so it still wasn't great). From those two Random Forest seems to perform marginally better.\n",
        "\n",
        "Linear regression had a terrible accuracy on the \"1\" targets, but otherwise was performing decently.\n",
        "\n",
        "TabPFN was always predicting \"0\", but it's probably due to very high imbalance ratio of the dataset and the fact that the training had to be limited to the first 1000 entries due to Colab performance constraints."
      ],
      "metadata": {
        "id": "rji4tfa0cCyK"
      }
    }
  ]
}